# -*- coding: utf-8 -*-
"""hope.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e5khy7fTz-DBIt8MuGgRqOU048FDGKJ7
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re, string, os, warnings
warnings.filterwarnings('ignore')

from bs4 import BeautifulSoup
from collections import Counter
from wordcloud import WordCloud
from textblob import TextBlob

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier
from sklearn.svm import LinearSVC
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from scipy.sparse import hstack
import joblib

"""#LOADING DATASET FROM KAGGLE

"""

import kagglehub
path = kagglehub.dataset_download("clmentbisaillon/fake-and-real-news-dataset")
print("Path to dataset files:", path)

fake_df = pd.read_csv(f'{path}/Fake.csv')
true_df = pd.read_csv(f'{path}/True.csv')

fake_df['label'] = 'fake'
true_df['label'] = 'real'

df = pd.concat([fake_df, true_df], axis=0).reset_index(drop=True)
print("Dataset shape before cleaning:", df.shape)

"""#nedt"""

df.info()
print("Null values per column:\n", df.isnull().sum())
print("Duplicate entries:", df.duplicated().sum())
#add combined col
df['combined_text'] = df['title'].fillna('') + ' ' + df['text'].fillna('')
df = df.drop(columns=['date', 'title', 'text'], errors='ignore')
df = df.drop_duplicates()
#label distribution
sns.countplot(data=df, x='label', palette='cool')
plt.title('Label Distribution (Fake vs Real)')
plt.show()

"""#wordcloud"""

# Wordcloud visualization for fake and real news
fake_text = ' '.join(df[df['label']=='fake']['combined_text'][:500])
real_text = ' '.join(df[df['label']=='real']['combined_text'][:500])
fig, ax = plt.subplots(1, 2, figsize=(15, 6))

fake_wc = WordCloud(width=600, height=400, background_color='white', colormap='Reds').generate(fake_text)
real_wc = WordCloud(width=600, height=400, background_color='white', colormap='Blues').generate(real_text)

ax[0].imshow(fake_wc, interpolation='bilinear')
ax[0].set_title("Fake News WordCloud", fontsize=14)
ax[0].axis("off")

ax[1].imshow(real_wc, interpolation='bilinear')
ax[1].set_title("Real News WordCloud", fontsize=14)
ax[1].axis("off")

plt.tight_layout()
plt.show()


print("Dataset shape after cleaning:", df.shape)

"""#Cleanign & Preprocessing"""

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
nltk.download('stopwords', quiet=True)

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def preprocess_text_stemming(text):
    if pd.isna(text) or not isinstance(text, str):
        return ""
    soup = BeautifulSoup(text, 'html.parser')
    text = soup.get_text(separator=' ')
    text = re.sub(r'http\S+|www\S+', '', text)
    text = text.lower()
    tokens = [stemmer.stem(w) for w in text.split() if w.isalpha() and w not in stop_words]
    return ' '.join(tokens)

df['cleaned_text'] = [preprocess_text_stemming(t) for t in df['combined_text']]
print("Preprocessing complete.")

"""#SAVING CLEANED DATASET"""

# Save the final cleaned DataFrame to a CSV file
df.to_csv('fake_news.csv', index=False)

"""#EDA"""

df.columns

# EDA: Most common words for fake and real
real_words = ' '.join(df[df['label']=='real']['cleaned_text'])
fake_words = ' '.join(df[df['label']=='fake']['cleaned_text'])

def plot_top_words(text, title, n=20):
    words = text.split()
    counter = Counter(words)
    common = counter.most_common(n)
    terms, freqs = zip(*common)
    plt.figure(figsize=(10,5))
    sns.barplot(x=list(freqs), y=list(terms), palette='viridis')
    plt.title(title)
    plt.show()

plot_top_words(real_words, 'Top Real News Words')
plot_top_words(fake_words, 'Top Fake News Words')

df.shape

"""#FEATURE ENGG"""

def extract_features(text):
    text = str(text)
    chars = len(text)
    words = text.split()
    word_count = len(words)
    avg_word_len = np.mean([len(w) for w in words]) if word_count > 0 else 0
    unique_ratio = len(set(words)) / (word_count + 1)
    punct_count = sum(1 for c in text if c in string.punctuation)
    num_exclam = text.count('!')
    num_digits = sum(1 for c in text if c.isdigit())
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity
    return [chars, word_count, avg_word_len, unique_ratio, punct_count, num_exclam, num_digits, polarity, subjectivity]

feature_names = ['char_count','word_count','avg_word_len','unique_ratio','punct_count','num_exclam','num_digits','polarity','subjectivity']
feature_df = pd.DataFrame(df['cleaned_text'].apply(lambda x: extract_features(x)).tolist(), columns=feature_names)

# Visualize feature distributions
feature_df[['char_count','word_count','avg_word_len','punct_count']].hist(bins=30, figsize=(10,8), color='#5DADE2')
plt.suptitle('Feature Distributions')
plt.show()

print("Feature engineering complete.")

"""#TF-IDF + FEATURE COMBINATON"""

tfidf = TfidfVectorizer(ngram_range=(1,2), max_df=0.8, min_df=5, max_features=20000)
X_text = tfidf.fit_transform(df['cleaned_text'])
scaler = StandardScaler()
X_num = scaler.fit_transform(feature_df)
X = hstack([X_text, X_num])
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("Combined feature matrix:", X.shape)

"""# ENSEMBLE MODEL(LOGISTIC REGRESSION + RANDOM FOREST)"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# --- 1. Define Base Models with Optimized Tuning for Reduced Overfitting ---

# Logistic Regression (LR): Stronger regularization (C=0.1) for better generalization.
log_reg = LogisticRegression(
    solver='liblinear',
    random_state=42,
    class_weight='balanced',
    C=0.1  # <--- Tuned: Stronger Regularization
)

# Random Forest (RF): Tighter constraints to prevent deep, overfit trees.
rand_forest = RandomForestClassifier(
    n_estimators=150, # Slightly more trees for stability
    max_depth=15, # <--- Tighter depth constraint (reduced from 50/20)
    min_samples_leaf=10, # <--- Increased constraint: requires more samples per leaf
    max_features='sqrt', # Limiting features considered at each split
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'
)

# --- 2. Create the Soft Voting Ensemble ---
# NOTE: All models must support 'predict_proba' for soft voting.
ensemble = VotingClassifier(
    estimators=[
        ('lr', log_reg),
        ('rf', rand_forest)
    ],
    voting='soft', # <--- Changed to Soft Voting
    n_jobs=-1
)

# Store models for comparison
models = {
    'Logistic Regression': log_reg,
    'Random Forest': rand_forest,
    'Soft Ensemble': ensemble
}

# Dictionary to store results
results = {}

print("Models Initialized with Tuned Parameters (C=0.1, RF max_depth=15, min_samples_leaf=10).")
print("---" * 25)

# --- 3. Train and Evaluate Models ---
for name, model in models.items():
    print(f"\n{'='*15} {name} {'='*15}")

    # Train the model
    model.fit(X_train, y_train)

    # Predictions on both train and test sets
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Accuracy metrics
    train_acc = accuracy_score(y_train, y_train_pred)
    test_acc = accuracy_score(y_test, y_test_pred)

    results[name] = {'Train Accuracy': train_acc, 'Test Accuracy': test_acc}

    print(f"Train Accuracy: {train_acc:.4f}")
    print(f"Test Accuracy : {test_acc:.4f}")

    print("\nClassification Report (Test):")
    print(classification_report(y_test, y_test_pred))

    # Confusion matrix for the Ensemble (Visualization for the final model)
    if name == 'Soft Ensemble':
        cm = confusion_matrix(y_test, y_test_pred)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
        disp.plot(cmap=plt.cm.Blues)
        plt.title(f"{name} Confusion Matrix")
        plt.show()

# --- 4. Print Summary of All Model Accuracies ---
print("\n\n==== Summary of All Model Accuracies ====")
print("| Model | Training Accuracy | Testing Accuracy |")
print("|:---|:---:|:---:|")
for name, acc in results.items():
    print(f"| {name:<20} | {acc['Train Accuracy']:.4f} | {acc['Test Accuracy']:.4f} |")

"""#ENSEMBLE MODEL ( SVM + LOGISTIC REG + PAC)"""

# from sklearn.svm import LinearSVC
# from sklearn.linear_model import PassiveAggressiveClassifier
# from sklearn.ensemble import RandomForestClassifier, VotingClassifier
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


# svm = LinearSVC(C=0.01, random_state=42)
# pac = PassiveAggressiveClassifier(max_iter=1000, random_state=42,C= 0.001)
# rf = RandomForestClassifier(
#     n_estimators=100,
#     max_depth=10,
#     random_state=42,
#     n_jobs=-1  # Use all CPU cores
# )

# # Ensemble model (hard voting)
# ensemble = VotingClassifier(
#     estimators=[
#         ('svm', svm),
#         ('pac', pac),
#         ('rf', rf)
#     ],
#     voting='hard'
# )

# # Store models for comparison
# models = {
#     'SVM': svm,
#     'Passive Aggressive': pac,
#     'Random Forest': rf,
#     'Ensemble': ensemble
# }

# # Dictionary to store results
# results = {}

# # Train and evaluate models
# for name, model in models.items():
#     print(f"\n{'='*20} {name} {'='*20}")
#     model.fit(X_train, y_train)

#     # Predictions on both train and test sets
#     y_train_pred = model.predict(X_train)
#     y_test_pred = model.predict(X_test)

#     # Accuracy metrics
#     train_acc = accuracy_score(y_train, y_train_pred)
#     test_acc = accuracy_score(y_test, y_test_pred)

#     results[name] = {'Train Accuracy': train_acc, 'Test Accuracy': test_acc}

#     print(f"Train Accuracy: {train_acc:.4f}")
#     print(f"Test Accuracy : {test_acc:.4f}")
#     print("\nClassification Report (Test):")
#     print(classification_report(y_test, y_test_pred))

#     # Optional: Confusion matrix (to analyze misclassifications)
#     cm = confusion_matrix(y_test, y_test_pred)
#     print("Confusion Matrix:\n", cm)

# # Print summary of all model accuracies
# print("\n\n==== Summary of All Models ====")
# for name, acc in results.items():
#     print(f"{name:<20} | Train: {acc['Train Accuracy']:.4f} | Test: {acc['Test Accuracy']:.4f}")

# # Model comparison chart (train vs test)
# plt.figure(figsize=(8,5))
# bar_data = pd.DataFrame(results).T
# bar_data.plot(kind='bar', figsize=(10,6), color=['#5DADE2', '#48C9B0'])
# plt.title('Train vs Test Accuracy Comparison')
# plt.ylabel('Accuracy')
# plt.xticks(rotation=0)
# plt.grid(axis='y', linestyle='--', alpha=0.7)
# plt.legend(title='Accuracy Type')
# plt.tight_layout()
# plt.show()

# cv_scores = cross_val_score(ensemble, X, y, cv=5, scoring='accuracy')
# print("5-Fold Cross Validation Accuracy:", cv_scores.mean())

# # Confusion matrix for Ensemble
# y_pred_ens = ensemble.predict(X_test)
# cm = confusion_matrix(y_test, y_pred_ens, labels=['real','fake'])
# ConfusionMatrixDisplay(cm, display_labels=['Real','Fake']).plot(cmap='Blues')
# plt.title('Confusion Matrix - Ensemble Model')
# plt.show()

"""#testing ensemble model"""

print("\nSAMPLE TEST CASES\n")

sample_texts = [
    'Authorities in Nigeria are increasing efforts to tackle investment scams, especially those involving crypto platforms.',
    'Breaking News: Trump becomes the president of india',
    'Bomb blast in Delhi on 10 November 2025',
    'India Women Crickt Team won the Worldcup in 2025',
    'Modi is the Prime Minister of India',
    'Draupadi Murmu is the President of India',
    'U.S., North Korea clash at U.N. arms forum on nuclear threat',
    'Watch This Awesome Mashup of Michael Flynn Leading The â€˜Lock Her Upâ€™ Chant As He Goes Off To Court (VIDEO) Donald Trump s disgraced National Security Adviser Michael Flynn has just plead guilty to lying to the FBI   a felony. He has also agreed to testify against Trump in exchange for leniency from Special Counsel Robert Mueller s team. The irony here is beyond delicious   especially since Flynn infamously led the  LOCK HER UP!  chants at the 2016 Republican National Convention, saying that Hillary Clinton was some kind of criminal, and that if Trump was elected they d be able to put her in jail, where many Trump supporters believe she belongs. Well, now the tables are turned, and it is Flynn who will be heading to jail, and the people who realize who the REAL criminals are have been having a field day. Perhaps one of the best pieces of Twitter schaudenfraude is this video of Flynn heading into court to plead guilty with the  Lock her up!  chant being played:I mashed up Michael Flynn s perp walk with audio of him leading a  lock her up  chant. pic.twitter.com/L1o5CjJXrQ  Adam Smith (@asmith83) December 1, 2017This is BEYOND awesome. These fools thought they d get a chance to put Hillary Clinton in jail as if we live in some kind of banana republic. Instead, they are all turning on each other in order to save their own asses in the best circular firing squad any of us ever could have imagined. Michael Flynn is going to sing like a canary so that he can keep himself and his equally criminal son out of federal prison   and railroad the entire Trump crime family into the slammer   just where they belong.The GOP made a deal with the devil when their ignorant, bigoted voters chose this unfit orange overlord to be their presidential nominee. Now, they are very likely to rue the day they ever heard the name Donald Trump.Featured image via Chip Somodevilla/Getty Images",watch awesom mashup michael flynn lead chant goe court donald trump disgrac nation secur advis michael flynn plead guilti lie fbi also agre testifi trump exchang lenienc special counsel robert mueller ironi beyond delici especi sinc flynn infam led lock chant republican nation say hillari clinton kind trump elect abl put mani trump support believ tabl flynn head peopl realiz real crimin field perhap one best piec twitter schaudenfraud video flynn head court plead guilti lock chant mash michael flynn perp walk audio lead lock adam smith decemb beyond fool thought get chanc put hillari clinton jail live kind banana turn order save ass best circular fire squad us ever could michael flynn go sing like canari keep equal crimin son feder prison railroad entir trump crime famili slammer gop made deal devil bigot voter chose unfit orang overlord presidenti like rue day ever heard name donald imag via chip imag',
    'The government successfully passed a new education reform bill today, aiming to improve access to schools and increase funding for teachers. Lawmakers and citizens praised the initiative as a major step forward for the countryâ€™s future.'
]

# Function to preprocess, extract features, and predict using the ensemble model
def predict_texts(texts):
    for text in texts:
        cleaned = preprocess_text_stemming(text)
        feats = extract_features(cleaned)
        X_tfidf = tfidf.transform([cleaned])
        X_num = scaler.transform([feats])
        X_comb = hstack([X_tfidf, X_num])
        pred = ensemble.predict(X_comb)[0]
        print(f"News: {text[:100]}...")
        print(f"Predicted Label: {pred.upper()}\n")

# Run the predictions
predict_texts(sample_texts)

"""#SAVING THE ENEMBLE MODEL"""

joblib.dump(ensemble, 'ensemble_model.pkl')
joblib.dump(tfidf, 'tfidf_vectorizer.pkl')
joblib.dump(scaler, 'numeric_scaler.pkl')
print("Saved model and vectorizer artifacts.")

"""#DL FOR CLASSIFYING NEW FAKE NEWS ===> BERT"""

# Install required libraries (only if needed, otherwise skip)
# ! pip install transformers

import numpy as np
import pandas as pd
import transformers
from transformers import AutoModel, BertTokenizerFast
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from torch.optim import AdamW # FIXED: AdamW is imported from torch.optim

# Specify GPU/CPU (This will use T4 GPU if available in Colab)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f'Using device: {device}')

import kagglehub

# 1. Download the dataset from Kaggle (Source of the data)
print("Downloading dataset from Kaggle...")
path = kagglehub.dataset_download("clmentbisaillon/fake-and-real-news-dataset")

# 2. Load the source files
fake_df = pd.read_csv(f'{path}/Fake.csv')
true_df = pd.read_csv(f'{path}/True.csv')

# 3. Add integer labels (0 for Real, 1 for Fake)
fake_df['label'] = 1
true_df['label'] = 0

# 4. Concatenate dataframes
data = pd.concat([fake_df, true_df], axis=0).sample(frac=1, random_state=2018).reset_index(drop=True)

# 5. Create the combined text column (title + text)
data['combined_text'] = data['title'].fillna('') + ' ' + data['text'].fillna('')

# 6. --- CRITICAL CLEANING STEP: REMOVE DUPLICATES ---
initial_rows = data.shape[0]
data.drop_duplicates(subset=['combined_text'], inplace=True)
final_rows = data.shape[0]
data.reset_index(drop=True, inplace=True)

# 7. Final cleaning and verification
data.dropna(subset=['combined_text'], inplace=True)
data['label'] = data['label'].astype(int)

print(f"\nSource data loaded and cleaned successfully.")
print(f"Initial rows: {initial_rows}, Duplicates removed: {initial_rows - final_rows}")
print(f"Final Shape: {data.shape}")
print(f"Label distribution:\n{data['label'].value_counts()}")

# 1. Data Splitting (70:15:15 ratio)
train_text, temp_text, train_labels, temp_labels = train_test_split(
    data['combined_text'], data['label'], random_state=2018, test_size=0.3, stratify=data['label']
)
val_text, test_text, val_labels, test_labels = train_test_split(
    temp_text, temp_labels, random_state=2018, test_size=0.5, stratify=temp_labels
)

# 2. Load BERT model and tokenizer
MAX_LENGHT = 128
bert = AutoModel.from_pretrained('bert-base-uncased')
tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')

# 3. Tokenize and encode sequences
def encode_data(text_list):
    return tokenizer.batch_encode_plus(
        text_list, max_length=MAX_LENGHT, padding='max_length', truncation=True
    )

tokens_train = encode_data(train_text.tolist())
tokens_val = encode_data(val_text.tolist())
tokens_test = encode_data(test_text.tolist())

# 4. Convert to PyTorch tensors and move to device
def create_tensors(tokens, labels):
    # Ensure labels are converted to a list before tensor conversion
    y_list = labels.tolist() if isinstance(labels, pd.Series) else labels

    seq = torch.tensor(tokens['input_ids']).to(device)
    mask = torch.tensor(tokens['attention_mask']).to(device)
    y = torch.tensor(y_list).to(device)
    return seq, mask, y

train_seq, train_mask, train_y = create_tensors(tokens_train, train_labels)
val_seq, val_mask, val_y = create_tensors(tokens_val, val_labels)
test_seq, test_mask, test_y = create_tensors(tokens_test, test_labels)

# 5. Create DataLoaders
batch_size = 32
train_data = TensorDataset(train_seq, train_mask, train_y)
train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)
val_data = TensorDataset(val_seq, val_mask, val_y)
val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)

print(f"Data split and DataLoaders created. Max Length used: {MAX_LENGHT}")

import torch.nn as nn
from torch.optim import AdamW
from transformers import AutoModel # Re-importing just in case, though likely present

# Assuming 'bert' and 'device' are defined from previous steps

# --- Model Architecture ---

# Freeze base BERT parameters to save time and memory
for param in bert.parameters():
    param.requires_grad = False

class BERT_Arch(nn.Module):
    def __init__(self, bert):
      super(BERT_Arch, self).__init__()
      self.bert = bert
      self.dropout = nn.Dropout(0.1)
      # BERT base model outputs a 768-dimensional vector
      self.fc1 = nn.Linear(768, 512)
      self.relu = nn.ReLU()
      self.fc2 = nn.Linear(512, 2) # Output layer for 2 classes (Fake/Real)
      self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, sent_id, mask):
      # Pass input through BERT
      # pooler_output is the representation of the [CLS] token used for classification
      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']

      # Pass through custom layers
      x = self.fc1(cls_hs)
      x = self.relu(x)
      x = self.dropout(x)
      x = self.fc2(x)
      x = self.softmax(x)
      return x

# Initialize and setup
model = BERT_Arch(bert).to(device)
# Use AdamW optimizer with a low learning rate
optimizer = AdamW(model.parameters(), lr=1e-5)
cross_entropy = nn.NLLLoss()
epochs = 3


# --- Training and Evaluation Functions ---

def train():
    model.train()
    total_loss = 0
    for step, batch in enumerate(train_dataloader):
        sent_id, mask, labels = batch
        model.zero_grad()
        preds = model(sent_id, mask)
        loss = cross_entropy(preds, labels)
        total_loss += loss.item()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
    return total_loss / len(train_dataloader)

def evaluate():
    model.eval()
    total_loss = 0
    for step, batch in enumerate(val_dataloader):
        sent_id, mask, labels = batch
        with torch.no_grad():
            preds = model(sent_id, mask)
            loss = cross_entropy(preds, labels)
            total_loss += loss.item()
    return total_loss / len(val_dataloader)

print("Model architecture and training functions defined.")

# =======================================================
# 1. SETUP & IMPORTS
# =======================================================
import numpy as np
import pandas as pd
# Import AdamW from torch.optim, not transformers, to avoid the previous ImportError
from transformers import AutoModel, BertTokenizerFast
from torch.optim import AdamW
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
import os
import gc

# Data downloading library
import kagglehub # <-- Incorporated for data loading

# Specify GPU/CPU device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# =======================================================
# 2. DATA LOADING AND PREPROCESSING (CRITICAL FIX)
# =======================================================
print("Loading and preparing data from Kaggle...")

# --- Data Loading using kagglehub (as per user request) ---
try:
    path = kagglehub.dataset_download("clmentbisaillon/fake-and-real-news-dataset")
    print("Path to dataset files:", path)

    # Load files using the downloaded path
    fake_df = pd.read_csv(f'{path}/Fake.csv')
    true_df = pd.read_csv(f'{path}/True.csv')

except Exception as e:
    # This might happen if kagglehub is not installed or permissions are an issue
    print(f"ERROR: Failed to download dataset via kagglehub. Attempting local load.")
    # Fallback to local files if download fails (for completeness, though it failed before)
    try:
        fake_df = pd.read_csv('Fake.csv')
        true_df = pd.read_csv('True.csv')
    except FileNotFoundError:
        raise FileNotFoundError(
            "FATAL ERROR: Could not download files or find them locally. "
            "Please ensure the data source is accessible."
        )

# --- Labeling and Merging (as per user request) ---
fake_df['label'] = 'fake'
true_df['label'] = 'real'
df = pd.concat([fake_df, true_df], axis=0).reset_index(drop=True)
print(f"Dataset shape before cleaning: {df.shape}")

# --- Cleaning (Remove Duplicates) ---
# Combine 'title' and 'text' to identify true duplicates across the entire article
df['combined_text'] = df['title'].fillna('') + ' ' + df['text'].fillna('')
initial_rows = df.shape[0]
df.drop_duplicates(subset=['combined_text'], inplace=True)
final_rows = df.shape[0]
df.reset_index(drop=True, inplace=True)
print(f"Duplicates removed: {initial_rows - final_rows}")
print(f"Dataset shape after cleaning: {df.shape}")

# Create the binary label 'label_id' (1 for fake, 0 for real)
df['label_id'] = df['label'].apply(lambda x: 1 if x == 'fake' else 0)

# We will use the 'title' column for sequence modeling as specified in your original notebook structure.
# If you intended to use 'combined_text', you would swap 'df['title']' for 'df['combined_text']'.
TEXT_COLUMN = df['title']
LABEL_COLUMN = df['label_id']
TARGET_COLUMN = df['label']


# Train-Validation-Test set split (70:15:15 ratio, stratified by original label)
train_text, temp_text, train_labels, temp_labels = train_test_split(
    TEXT_COLUMN, LABEL_COLUMN, random_state=2018, test_size=0.3, stratify=TARGET_COLUMN
)
val_text, test_text, val_labels, test_labels = train_test_split(
    temp_text, temp_labels, random_state=2018, test_size=0.5, stratify=temp_labels
)

# Load BERT model and tokenizer
bert = AutoModel.from_pretrained('bert-base-uncased')
tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')

# Set Max Length
MAX_LENGHT = 15

# =======================================================
# 3. TOKENIZATION & TENSOR CONVERSION
# =======================================================
print("Tokenizing and creating tensors...")

tokens_train = tokenizer.batch_encode_plus(
    train_text.tolist(), max_length = MAX_LENGHT, padding='max_length', truncation=True
)
tokens_val = tokenizer.batch_encode_plus(
    val_text.tolist(), max_length = MAX_LENGHT, padding='max_length', truncation=True
)
tokens_test = tokenizer.batch_encode_plus(
    test_text.tolist(), max_length = MAX_LENGHT, padding='max_length', truncation=True
)

# Convert lists to tensors
train_seq = torch.tensor(tokens_train['input_ids'])
train_mask = torch.tensor(tokens_train['attention_mask'])
train_y = torch.tensor(train_labels.tolist())

val_seq = torch.tensor(tokens_val['input_ids'])
val_mask = torch.tensor(tokens_val['attention_mask'])
val_y = torch.tensor(val_labels.tolist())

test_seq = torch.tensor(tokens_test['input_ids'])
test_mask = torch.tensor(tokens_test['attention_mask'])
test_y = torch.tensor(test_labels.tolist())

# =======================================================
# 4. DATA LOADERS
# =======================================================
batch_size = 32

train_data = TensorDataset(train_seq, train_mask, train_y)
train_sampler = RandomSampler(train_data)
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

val_data = TensorDataset(val_seq, val_mask, val_y)
val_sampler = SequentialSampler(val_data)
val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)

# =======================================================
# 5. MODEL ARCHITECTURE
# =======================================================
# Freeze BERT parameters (Feature Extraction)
for param in bert.parameters():
    param.requires_grad = False

class BERT_Arch(nn.Module):
    def __init__(self, bert):
      super(BERT_Arch, self).__init__()
      self.bert = bert
      self.dropout = nn.Dropout(0.1)
      self.relu = nn.ReLU()
      self.fc1 = nn.Linear(768, 512)
      self.fc2 = nn.Linear(512, 2)
      self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, sent_id, mask):
      cls_hs = self.bert(sent_id.to(device), attention_mask=mask.to(device))['pooler_output']
      x = self.fc1(cls_hs)
      x = self.relu(x)
      x = self.dropout(x)
      x = self.fc2(x)
      x = self.softmax(x)
      return x

model = BERT_Arch(bert).to(device)

# =======================================================
# 6. OPTIMIZER, LOSS & EPOCHS
# =======================================================
optimizer = AdamW(model.parameters(), lr = 3e-5)
cross_entropy = nn.NLLLoss()
epochs = 3
weights_save_path = 'c2_new_model_weights.pt'

# =======================================================
# 7. TRAINING AND EVALUATION FUNCTIONS
# =======================================================
def train():
    model.train()
    total_loss = 0

    for step, batch in enumerate(train_dataloader):
        if step % 50 == 0 and not step == 0:
            print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.')

        sent_id, mask, labels = batch

        model.zero_grad()
        preds = model(sent_id, mask)
        loss = cross_entropy(preds, labels.to(device))
        total_loss += loss.item()

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()

        # Clean up memory
        del sent_id, mask, labels, preds, loss
        if device.type == 'cuda':
             torch.cuda.empty_cache()

    avg_loss = total_loss / len(train_dataloader)
    return avg_loss

def evaluate():
    print("\nEvaluating...")
    model.eval()
    total_loss = 0

    for step, batch in enumerate(val_dataloader):
        if step % 50 == 0 and not step == 0:
            print(f'  Batch {step:>5,}  of  {len(val_dataloader):>5,}.')

        sent_id, mask, labels = batch

        with torch.no_grad():
            preds = model(sent_id, mask)
            loss = cross_entropy(preds, labels.to(device))
            total_loss += loss.item()

        # Clean up memory
        del sent_id, mask, labels, preds, loss
        if device.type == 'cuda':
             torch.cuda.empty_cache()

    avg_loss = total_loss / len(val_dataloader)
    return avg_loss

# =======================================================
# 8. THE TRAINING LOOP EXECUTION
# =======================================================
print("\nStarting Training Loop...")
best_valid_loss = float('inf')
train_losses=[]
valid_losses=[]

for epoch in range(epochs):
    print(f'\n Epoch {epoch + 1} / {epochs}')

    train_loss = train()
    valid_loss = evaluate()

    if valid_loss < best_valid_loss:
        best_valid_loss = valid_loss
        torch.save(model.state_dict(), weights_save_path)
        print("Model weights saved.")

    train_losses.append(train_loss)
    valid_losses.append(valid_loss)

    print(f'\nTraining Loss: {train_loss:.3f}')
    print(f'Validation Loss: {valid_loss:.3f}')

print(f"\nTraining Complete. Best weights saved to: {weights_save_path}")

# Explicitly clear memory after training
del train_dataloader, val_dataloader
gc.collect()
if device.type == 'cuda':
    torch.cuda.empty_cache()

# 1. SETUP & IMPORTS
# =======================================================
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from transformers import AutoModel, BertTokenizerFast
import gc

# Specify GPU/CPU device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# =======================================================
# 2. MODEL ARCHITECTURE (Copied from bert_train.py)
# Must be defined to load saved weights
# =======================================================
class BERT_Arch(nn.Module):
    def __init__(self, bert):
      super(BERT_Arch, self).__init__()
      self.bert = bert
      self.dropout = nn.Dropout(0.1)
      self.relu = nn.ReLU()
      self.fc1 = nn.Linear(768, 512)
      self.fc2 = nn.Linear(512, 2)
      self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, sent_id, mask):
      cls_hs = self.bert(sent_id.to(device), attention_mask=mask.to(device))['pooler_output']
      x = self.fc1(cls_hs)
      x = self.relu(x)
      x = self.dropout(x)
      x = self.fc2(x)
      x = self.softmax(x)
      return x

# =======================================================
# 3. LOAD MODEL AND WEIGHTS
# =======================================================
try:
    # Configuration matches the training script
    weights_save_path = 'c2_new_model_weights.pt'
    MAX_LENGHT = 15

    # Load pre-trained BERT and tokenizer
    bert = AutoModel.from_pretrained('bert-base-uncased')
    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')

    # Freeze BERT parameters (Feature Extraction)
    for param in bert.parameters():
        param.requires_grad = False

    # Instantiate the model and load the trained weights
    model = BERT_Arch(bert).to(device)
    model.load_state_dict(torch.load(weights_save_path, map_location=device))
    model.eval() # Set model to evaluation mode
    print(f"Successfully loaded model weights from: {weights_save_path}")

except Exception as e:
    print(f"ERROR: Could not load model or weights. Ensure '{weights_save_path}' exists.")
    print(f"Details: {e}")
    exit()

# =======================================================
# 4. INFERENCE FUNCTION
# =======================================================
def predict_news_type(texts):
    """Tokenizes a list of texts and returns the predicted label."""

    # Tokenize the input texts
    tokens_inf = tokenizer.batch_encode_plus(
        texts, max_length = MAX_LENGHT, padding='max_length', truncation=True
    )

    seq = torch.tensor(tokens_inf['input_ids'])
    mask = torch.tensor(tokens_inf['attention_mask'])

    with torch.no_grad():
        preds = model(seq, mask)
        # Get the index with the highest probability
        predicted_labels = torch.argmax(preds, dim=1).cpu().numpy()

    return predicted_labels

# =======================================================
# 5. RUN TEST CASES
# =======================================================
test_cases = [
    " WATCH: Lindsey Graham Trashes Media For Portraying Trump As â€˜Kooky,â€™ Forgets His Own Words The media has been talking all day about Trump and the Republican Party s scam of a tax bill; as well as the sheer obsequiousness of Trump s cabinet, and then members of Congress, after their tax scam was all but passed. But the media isn t quite saying what Trump wants. They ve been doing analysis and discussion all day long rather than praising it for the grand achievement Trump believes it is. The GOP has increasingly sounded exactly like Trump when it comes to media coverage, and coverage of the tax scam is no different. Coverage of Trump in general hasn t changed.Today, Lindsey Graham went after the media for portraying Trump as a  kook,  and unfit for office (they wouldn t be doing their job if they weren t telling the truth, though). Graham said: You know what concerns me about the American press is this endless, endless attempt to label the guy as some kind of kook; not fit to be president. Jake Tapper notes that he himself has never labeled Trump that way. But then he points out something rather odd about Graham s opinion. Take a look at the short video clip below:Lindsey Graham today: I m concerned by the media s attempt to label Trump as a kook or not fit to be President.Lindsey Graham in 2016:  I think he s a kook. I think he s crazy. I think he s unfit for office.  pic.twitter.com/hIxs3DciO8  Tomthunkit  (@TomthunkitsMind) December 17, 2017There it is, out of Graham s own mouth. He parroted himself. In 2016, he used the exact words to describe Trump that he said the media is using today. Freudian slip?Featured image via video screen capture,lindsey graham trash media portray trump forget word media talk day trump republican parti scam tax well sheer obsequi trump member tax scam media quit say trump analysi discuss day long rather prais grand achiev trump believ gop increasingli sound exactli like trump come media coverag tax scam coverag trump gener lindsey graham went media portray trump unfit offic job tell graham know concern american press endless attempt label guy kind fit jake tapper note never label trump point someth rather odd graham take look short video clip graham concern media attempt label trump kook fit graham think think think unfit tomthunkit decemb graham parrot use exact word describ trump said media use freudian imag via video screen captur",
    'Authorities in Nigeria are increasing efforts to tackle investment scams, especially those involving crypto platforms.',
    '" WATCH: Lindsey Graham Trashes Media For Portraying Trump As â€˜Kooky,â€™ Forgets His Own Words The media has been talking all day about Trump and the Republican Party s scam of a tax bill; as well as the sheer obsequiousness of Trump s cabinet, and then members of Congress, after their tax scam was all but passed. But the media isn t quite saying what Trump wants. They ve been doing analysis and discussion all day long rather than praising it for the grand achievement Trump believes it is. The GOP has increasingly sounded exactly like Trump when it comes to media coverage, and coverage of the tax scam is no different. Coverage of Trump in general hasn t changed.Today, Lindsey Graham went after the media for portraying Trump as a  kook,  and unfit for office (they wouldn t be doing their job if they weren t telling the truth, though). Graham said: You know what concerns me about the American press is this endless, endless attempt to label the guy as some kind of kook; not fit to be president. Jake Tapper notes that he himself has never labeled Trump that way. But then he points out something rather odd about Graham s opinion. Take a look at the short video clip below:Lindsey Graham today: I m concerned by the media s attempt to label Trump as a kook or not fit to be President.Lindsey Graham in 2016:  I think he s a kook. I think he s crazy. I think he s unfit for office.  pic.twitter.com/hIxs3DciO8  Tomthunkit  (@TomthunkitsMind) December 17, 2017There it is, out of Graham s own mouth. He parroted himself. In 2016, he used the exact words to describe Trump that he said the media is using today. Freudian slip?Featured image via video screen capture",lindsey graham trash media portray trump forget word media talk day trump republican parti scam tax well sheer obsequi trump member tax scam media quit say trump analysi discuss day long rather prais grand achiev trump believ gop increasingli sound exactli like trump come media coverag tax scam coverag trump gener lindsey graham went media portray trump unfit offic job tell graham know concern american press endless attempt label guy kind fit jake tapper note never label trump point someth rather odd graham take look short video clip graham concern media attempt label trump kook fit graham think think think unfit tomthunkit decemb graham parrot use exact word describ trump said media use freudian imag via video screen captur',
    'India Women Crickt Team won the Worldcup in 2025',
    'Modi is the Prime Minister of India',
    'Bomb blast in Delhi on 10 November 2025',
    'Draupadi Murmu is the President of India',
    'India launches Operation Sindoor against Pakistan',
    'U.S., North Korea clash at U.N. arms forum on nuclear threat',
    'Watch This Awesome Mashup of Michael Flynn Leading The â€˜Lock Her Upâ€™ Chant As He Goes Off To Court (VIDEO) Donald Trump s disgraced National Security Adviser Michael Flynn has just plead guilty to lying to the FBI   a felony. He has also agreed to testify against Trump in exchange for leniency from Special Counsel Robert Mueller s team. The irony here is beyond delicious   especially since Flynn infamously led the  LOCK HER UP!  chants at the 2016 Republican National Convention, saying that Hillary Clinton was some kind of criminal, and that if Trump was elected they d be able to put her in jail, where many Trump supporters believe she belongs. Well, now the tables are turned, and it is Flynn who will be heading to jail, and the people who realize who the REAL criminals are have been having a field day. Perhaps one of the best pieces of Twitter schaudenfraude is this video of Flynn heading into court to plead guilty with the  Lock her up!  chant being played:I mashed up Michael Flynn s perp walk with audio of him leading a  lock her up  chant. pic.twitter.com/L1o5CjJXrQ  Adam Smith (@asmith83) December 1, 2017This is BEYOND awesome. These fools thought they d get a chance to put Hillary Clinton in jail as if we live in some kind of banana republic. Instead, they are all turning on each other in order to save their own asses in the best circular firing squad any of us ever could have imagined. Michael Flynn is going to sing like a canary so that he can keep himself and his equally criminal son out of federal prison   and railroad the entire Trump crime family into the slammer   just where they belong.The GOP made a deal with the devil when their ignorant, bigoted voters chose this unfit orange overlord to be their presidential nominee. Now, they are very likely to rue the day they ever heard the name Donald Trump.Featured image via Chip Somodevilla/Getty Images",watch awesom mashup michael flynn lead chant goe court donald trump disgrac nation secur advis michael flynn plead guilti lie fbi also agre testifi trump exchang lenienc special counsel robert mueller ironi beyond delici especi sinc flynn infam led lock chant republican nation say hillari clinton kind trump elect abl put mani trump support believ tabl flynn head peopl realiz real crimin field perhap one best piec twitter schaudenfraud video flynn head court plead guilti lock chant mash michael flynn perp walk audio lead lock adam smith decemb beyond fool thought get chanc put hillari clinton jail live kind banana turn order save ass best circular fire squad us ever could michael flynn go sing like canari keep equal crimin son feder prison railroad entir trump crime famili slammer gop made deal devil bigot voter chose unfit orang overlord presidenti like rue day ever heard name donald imag via chip imag',
    'The government successfully passed a new education reform bill today, aiming to improve access to schools and increase funding for teachers. Lawmakers and citizens praised the initiative as a major step forward for the countryâ€™s future.'
]

predictions = predict_news_type(test_cases)
label_map = {1: "FAKE NEWS (0)", 0: "REAL NEWS (1)"}

print("\n--- TEST CASE RESULTS ---")
results = []
for title, pred in zip(test_cases, predictions):
    result = label_map[pred]
    results.append({
        'Title': title,
        'Prediction': result
    })
    print(f"Title: '{title}'\nPrediction: {result}\n")

# Clean up memory
del model, bert, tokenizer
gc.collect()
if device.type == 'cuda':
    torch.cuda.empty_cache()





"""#SNA PART"""

import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import time # Streamlit animation ke liye zaruri
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore', category=UserWarning)

# --- 1. CONFIGURATION PARAMETERS (Constants) ---
N = 1000        # Number of nodes (Users)
M = 2           # Edges to attach (BA Network parameter)
BETA = 0.05     # Infection Rate (Probability of spreading)
GAMMA = 0.01    # Recovery Rate (Probability of stopping spread/Fact-checking)
DAYS = 100      # Total simulation time steps
INITIAL_INFECTED_COUNT = 5 # Number of initial source nodes
COLOR_MAP = {0: 'lightblue', 1: 'red', 2: 'lightgreen'} # 0=S, 1=I, 2=R

# --- 2. CORE UTILITY FUNCTION: SOURCE SELECTION ---

def get_initial_infected_nodes(graph: nx.Graph, initial_count: int, selection_type: str) -> list:
    """
    Selects the source nodes based on network centrality measures ('hubs' or 'bridges').
    """

    if selection_type == 'hubs':
        # Option 2A: HIGH DEGREE CENTRALITY (HUBS)
        # Hubs are nodes with the most connections
        centrality_map = dict(graph.degree())

    elif selection_type == 'bridges':
        # Option 2B: HIGH BETWEENNESS CENTRALITY (BRIDGES)
        # Bridges are nodes that control flow between clusters
        # k=min(N, 200) is used to speed up the calculation for large graphs.
        centrality_map = nx.betweenness_centrality(graph, k=min(len(graph), 200), seed=42)

    else:
        raise ValueError("Invalid selection_type. Must be 'hubs' or 'bridges'.")

    # Sort nodes by centrality score and select the top 'initial_count'
    sorted_nodes = sorted(centrality_map.items(), key=lambda item: item[1], reverse=True)
    top_spreader_ids = [node[0] for node in sorted_nodes[:initial_count]]

    return top_spreader_ids


# --- 3. MAIN DYNAMIC SNA ANALYSIS FUNCTION ---

def misinformation_spread_analysis_dynamic(source_selection: str):
    """
    Runs the BA-SIR simulation and returns the graph structure and
    the state of all nodes for every day (required for dynamic plotting).
    """

    # --- NETWORK SETUP ---
    G = nx.barabasi_albert_graph(N, M, seed=42)

    # --- INITIALISATION ---
    initial_infected_nodes = get_initial_infected_nodes(G, INITIAL_INFECTED_COUNT, source_selection)

    # Setup initial state: 0=S, 1=I, 2=R
    state = np.zeros(N, dtype=int)
    state[initial_infected_nodes] = 1

    # --- STORAGE FOR DYNAMIC VISUALIZATION ---
    # Stores the color list (state) for every day of the simulation
    all_color_lists = []

    # --- SIR SIMULATION LOOP ---
    for t in range(DAYS):
        # 1. Capture the current state's colors before the update (CRUCIAL)
        current_colors = [COLOR_MAP[state[node]] for node in G.nodes()]
        all_color_lists.append(current_colors)

        I_count = np.sum(state == 1)
        if I_count == 0:
            break

        next_state = state.copy()

        for i in range(N):
            if state[i] == 1:
                # Recovery Check (I -> R)
                if np.random.rand() < GAMMA:
                    next_state[i] = 2
                # Infection Check (S -> I)
                else:
                    for neighbor in G.neighbors(i):
                        if state[neighbor] == 0:
                            if np.random.rand() < BETA:
                                next_state[neighbor] = 1

        state = next_state

    # --- PRE-CALCULATE PLOTTING ELEMENTS (Performance) ---
    # Layout calculation is the slowest part, do it only once
    pos = nx.spring_layout(G, k=0.1, iterations=50, seed=42)
    degrees = dict(G.degree())
    node_sizes = [10 + (degrees[node] / N) * 2000 for node in G.nodes()]

    print(f"Simulation data captured for {len(all_color_lists)} days.")

    # Return all necessary data for the Streamlit dynamic plot function
    return G, pos, node_sizes, all_color_lists, len(all_color_lists)

# --- 4. STREAMLIT INTEGRATION EXAMPLE (For your teammate) ---
# NOTE: This block shows how your teammate will use the function in Streamlit.
# It requires the Streamlit library to run.
if __name__ == '__main__':
    try:
        import streamlit as st

        st.set_page_config(layout="wide")

        # --- DYNAMIC PLOTTING FUNCTION ---
        # This function takes the data returned by the SNA function and animates it.
        def plot_dynamic_spread(G, pos, node_sizes, all_color_lists, max_days, source_selection):
            st.markdown(f"## ðŸ•¸ï¸ Misinformation Spread from {source_selection.upper()}")

            # Placeholder for the dynamic plot
            graph_container = st.empty()

            # Animation Loop
            for day in range(max_days):
                fig, ax = plt.subplots(figsize=(10, 10))

                current_colors = all_color_lists[day]

                nx.draw_networkx_nodes(
                    G, pos, node_color=current_colors, node_size=node_sizes,
                    alpha=0.8, edgecolors='black', ax=ax
                )
                nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.1, ax=ax)

                ax.set_title(f"Day {day+1} - Spread Status (Source: {source_selection.upper()})", fontsize=16)
                ax.axis('off')

                # Update the placeholder in Streamlit
                graph_container.pyplot(fig)
                plt.close(fig)

                # Control the animation speed
                time.sleep(0.1)

            st.success("Animation complete! Check the final spread.")

        # --- STREAMLIT UI LOGIC ---
        st.title("BERT-Triggered Dynamic Spread Analysis")

        # BERT prediction result would go here
        FAKE_NEWS_DETECTED = True

        if FAKE_NEWS_DETECTED:
            st.header("Misinformation Detected! Run Simulation:")

            col1, col2 = st.columns(2)

            with col1:
                if st.button("Simulate from HUBS (2A)", key="hubs_btn"):
                    # 1. Run the SNA simulation (prepares data)
                    G, pos, node_sizes, all_color_lists, max_days = misinformation_spread_analysis_dynamic('hubs')
                    # 2. Animate the result
                    plot_dynamic_spread(G, pos, node_sizes, all_color_lists, max_days, 'Hubs')

            with col2:
                if st.button("Simulate from BRIDGES (2B)", key="bridges_btn"):
                    # 1. Run the SNA simulation (prepares data)
                    G, pos, node_sizes, all_color_lists, max_days = misinformation_spread_analysis_dynamic('bridges')
                    # 2. Animate the result
                    plot_dynamic_spread(G, pos, node_sizes, all_color_lists, max_days, 'Bridges')

    except ImportError:
        print("\n*** ERROR: Streamlit not found. Install Streamlit to run the demo block. ***")
        print("Required libraries: pip install streamlit networkx numpy matplotlib")









#dont use the code below...useless hai abhi

import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import os
import warnings

# Suppress minor warnings for cleaner output
warnings.filterwarnings('ignore', category=UserWarning)

# --- 1. CONFIGURATION PARAMETERS ---
N = 1000        # Number of nodes (Users)
M = 2           # Edges to attach (BA Network parameter)
BETA = 0.05     # Infection Rate (Probability of spreading)
GAMMA = 0.01    # Recovery Rate (Probability of stopping spread/Fact-checking)
DAYS = 100      # Total simulation time steps
TARGET_DAY = 20 # Day to capture the network snapshot for visualization
INITIAL_INFECTED_COUNT = 5 # Number of initial source nodes

# --- 2. CORE UTILITY FUNCTION: SOURCE SELECTION ---

def get_initial_infected_nodes(graph, initial_count, selection_type):
    """
    Selects the source nodes based on network centrality measures (Hubs or Bridges).

    Args:
        graph (nx.Graph): The BarabÃ¡si-Albert network.
        initial_count (int): Number of nodes to select as initial sources.
        selection_type (str): 'hubs' (High Degree) or 'bridges' (High Betweenness).

    Returns:
        list: IDs of the selected initial infected nodes.
    """

    if selection_type == 'hubs':
        # Option 2A: HIGH DEGREE CENTRALITY (HUBS)
        print("-> Selection: High Degree Centrality (Hubs)")
        # Hubs are nodes with the most direct connections/followers
        centrality_map = dict(graph.degree())

    elif selection_type == 'bridges':
        # Option 2B: HIGH BETWEENNESS CENTRALITY (BRIDGES)
        print("-> Selection: High Betweenness Centrality (Bridges)")
        # Bridges are nodes that control flow between different clusters
        # NOTE: Betweenness calculation is slow, so we use k for sampling on large N
        centrality_map = nx.betweenness_centrality(graph, k=min(len(graph), 200), seed=42)

    else:
        raise ValueError("Invalid selection_type. Use 'hubs' or 'bridges'.")

    # Sort the nodes based on their centrality score (descending)
    sorted_nodes = sorted(centrality_map.items(), key=lambda item: item[1], reverse=True)

    # Get the node IDs of the top spreaders
    top_spreader_ids = [node[0] for node in sorted_nodes[:initial_count]]

    print(f"-> Selected {initial_count} initial source nodes.")
    return top_spreader_ids


# --- 3. MAIN SNA ANALYSIS FUNCTION ---

def misinformation_spread_analysis(source_selection: str):
    """
    Runs the full BA-SIR simulation and generates plots based on the source selection.

    Args:
        source_selection (str): 'hubs' or 'bridges'

    Returns:
        tuple: File names of the generated plots ('network_snapshot.png', 'sir_time_series.png')
    """

    # --- NETWORK SETUP ---
    # Create the Scale-Free Network (mimics social media)
    G = nx.barabasi_albert_graph(N, M, seed=42)

    # --- INITIALISATION ---
    initial_infected_nodes = get_initial_infected_nodes(
        G, INITIAL_INFECTED_COUNT, source_selection
    )

    # Setup initial state: 0=S, 1=I, 2=R
    state = np.zeros(N, dtype=int)
    state[initial_infected_nodes] = 1 # Set selected top nodes as Infectious (1)

    # Store results for time series plot
    results = {'S': [], 'I': [], 'R': []}
    snapshot_state = None

    print("-> Starting SIR Simulation...")

    # --- SIR SIMULATION LOOP ---
    for t in range(DAYS):
        # Capture the state for the time series plot
        S_count = np.sum(state == 0)
        I_count = np.sum(state == 1)
        R_count = np.sum(state == 2)
        results['S'].append(S_count)
        results['I'].append(I_count)
        results['R'].append(R_count)

        # Capture the network snapshot at TARGET_DAY
        if t == TARGET_DAY:
            snapshot_state = state.copy()

        if I_count == 0:
            break

        next_state = state.copy()

        for i in range(N):
            if state[i] == 1: # If Infectious (Spreading)

                # 1. Recovery Check (I -> R): Probability GAMMA
                if np.random.rand() < GAMMA:
                    next_state[i] = 2

                # 2. Infection Check (S -> I): Probability BETA
                else:
                    for neighbor in G.neighbors(i):
                        if state[neighbor] == 0: # If Susceptible
                            if np.random.rand() < BETA:
                                next_state[neighbor] = 1

        state = next_state # Update the state for the next day

    # Ensure snapshot_state is set if simulation ended before TARGET_DAY
    if snapshot_state is None:
        snapshot_state = state.copy()

    print(f"-> Simulation completed in {t+1} days.")

    # --- 4. PLOTTING AND SAVING RESULTS ---

    # 4.1 Network Snapshot Plot
    network_filename = f"network_snapshot_{source_selection}.png"
    plt.figure(figsize=(12, 12))

    color_map = {0: 'lightblue', 1: 'red', 2: 'lightgreen'}
    node_colors = [color_map[snapshot_state[node]] for node in G.nodes()]

    degrees = dict(G.degree())
    node_sizes = [10 + (degrees[node] / N) * 2000 for node in G.nodes()]
    pos = nx.spring_layout(G, k=0.1, iterations=50, seed=42)

    nx.draw_networkx_nodes(
        G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8, edgecolors='black'
    )
    nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.1)

    plt.title(f'Network Spread (Source: {source_selection.upper()}) at Day {TARGET_DAY}', fontsize=16)

    # Add Legend
    plt.legend(handles=[
        plt.Line2D([0], [0], marker='o', color='w', label='Susceptible (S)', markerfacecolor='lightblue', markersize=10),
        plt.Line2D([0], [0], marker='o', color='w', label='Infectious (I - Spreading)', markerfacecolor='red', markersize=10),
        plt.Line2D([0], [0], marker='o', color='w', label='Removed (R - Recovered)', markerfacecolor='lightgreen', markersize=10)
    ], loc='upper right')
    plt.axis('off')
    plt.savefig(network_filename)
    plt.close()

    # 4.2 Time Series Plot (S, I, R Curves)
    timeseries_filename = f"sir_time_series_{source_selection}.png"
    plt.figure(figsize=(10, 6))
    time = np.arange(len(results['S']))
    plt.plot(time, results['S'], label='Susceptible (S)', color='blue')
    plt.plot(time, results['I'], label='Infectious (I - Spreading)', color='red')
    plt.plot(time, results['R'], label='Removed (R - Recovered)', color='green')

    plt.title(f'SIR Model Spread Over Time (Source: {source_selection.upper()})')
    plt.xlabel('Time (Days)')
    plt.ylabel('Number of Users')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.savefig(timeseries_filename)
    plt.close()

    print(f"-> Two plots saved: {network_filename} and {timeseries_filename}")
    return network_filename, timeseries_filename


# --- 5. STREAMLIT INTEGRATION EXAMPLE (For your reference) ---
# NOTE: This block will NOT run if you just import the function.
if __name__ == '__main__':
    # This simulates the user choosing the options in the UI
    print("--- DEMO 1: USER SELECTS HUBS (2A) ---")
    hubs_net, hubs_sir = misinformation_spread_analysis('hubs')

    print("\n--- DEMO 2: USER SELECTS BRIDGES (2B) ---")
    bridges_net, bridges_sir = misinformation_spread_analysis('bridges')

    print("\n--- DEMO COMPLETE ---")
    print(f"To use this in Streamlit, you will call misinformation_spread_analysis('hubs') or ('bridges') and display the saved image files.")

def classify_text(text):
    pred = predict_news_type([text])[0]  # Get single prediction
    return "Misinformation" if pred == 1 else "Real News"


